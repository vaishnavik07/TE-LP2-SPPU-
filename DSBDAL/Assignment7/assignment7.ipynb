{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in c:\\users\\vaishnavi\\appdata\\roaming\\python\\python311\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\vaishnavi\\appdata\\roaming\\python\\python311\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\vaishnavi\\appdata\\roaming\\python\\python311\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\vaishnavi\\appdata\\roaming\\python\\python311\\site-packages (from nltk) (2023.5.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vaishnavi\\appdata\\roaming\\python\\python311\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\vaishnavi\\appdata\\roaming\\python\\python311\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_text='A histogram is a graphical representation of the distribution of a dataset. It provides a visual summary of the frequencies or counts of data points falling within different ranges, also known as bins or intervals.In a histogram, the x-axis represents the range of values from the dataset, divided into equal-sized bins. The y-axis represents the frequency or count of data points falling within each bin. The height of each bar in the histogram corresponds to the number of data points falling within that bin.Histograms are commonly used to understand the distribution of continuous or numerical variables. They allow us to observe patterns, identify central tendencies, and assess the spread or dispersion of the data.'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**sentence tokenize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Vaishnavi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A histogram is a graphical representation of the distribution of a dataset.',\n",
       " 'It provides a visual summary of the frequencies or counts of data points falling within different ranges, also known as bins or intervals.In a histogram, the x-axis represents the range of values from the dataset, divided into equal-sized bins.',\n",
       " 'The y-axis represents the frequency or count of data points falling within each bin.',\n",
       " 'The height of each bar in the histogram corresponds to the number of data points falling within that bin.Histograms are commonly used to understand the distribution of continuous or numerical variables.',\n",
       " 'They allow us to observe patterns, identify central tendencies, and assess the spread or dispersion of the data.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenzied_text=sent_tokenize(my_text)\n",
    "tokenzied_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'histogram',\n",
       " 'is',\n",
       " 'a',\n",
       " 'graphical',\n",
       " 'representation',\n",
       " 'of',\n",
       " 'the',\n",
       " 'distribution',\n",
       " 'of',\n",
       " 'a',\n",
       " 'dataset',\n",
       " '.',\n",
       " 'it',\n",
       " 'provides',\n",
       " 'a',\n",
       " 'visual',\n",
       " 'summary',\n",
       " 'of',\n",
       " 'the',\n",
       " 'frequencies',\n",
       " 'or',\n",
       " 'counts',\n",
       " 'of',\n",
       " 'data',\n",
       " 'points',\n",
       " 'falling',\n",
       " 'within',\n",
       " 'different',\n",
       " 'ranges',\n",
       " ',',\n",
       " 'also',\n",
       " 'known',\n",
       " 'as',\n",
       " 'bins',\n",
       " 'or',\n",
       " 'intervals.in',\n",
       " 'a',\n",
       " 'histogram',\n",
       " ',',\n",
       " 'the',\n",
       " 'x-axis',\n",
       " 'represents',\n",
       " 'the',\n",
       " 'range',\n",
       " 'of',\n",
       " 'values',\n",
       " 'from',\n",
       " 'the',\n",
       " 'dataset',\n",
       " ',',\n",
       " 'divided',\n",
       " 'into',\n",
       " 'equal-sized',\n",
       " 'bins',\n",
       " '.',\n",
       " 'the',\n",
       " 'y-axis',\n",
       " 'represents',\n",
       " 'the',\n",
       " 'frequency',\n",
       " 'or',\n",
       " 'count',\n",
       " 'of',\n",
       " 'data',\n",
       " 'points',\n",
       " 'falling',\n",
       " 'within',\n",
       " 'each',\n",
       " 'bin',\n",
       " '.',\n",
       " 'the',\n",
       " 'height',\n",
       " 'of',\n",
       " 'each',\n",
       " 'bar',\n",
       " 'in',\n",
       " 'the',\n",
       " 'histogram',\n",
       " 'corresponds',\n",
       " 'to',\n",
       " 'the',\n",
       " 'number',\n",
       " 'of',\n",
       " 'data',\n",
       " 'points',\n",
       " 'falling',\n",
       " 'within',\n",
       " 'that',\n",
       " 'bin.histograms',\n",
       " 'are',\n",
       " 'commonly',\n",
       " 'used',\n",
       " 'to',\n",
       " 'understand',\n",
       " 'the',\n",
       " 'distribution',\n",
       " 'of',\n",
       " 'continuous',\n",
       " 'or',\n",
       " 'numerical',\n",
       " 'variables',\n",
       " '.',\n",
       " 'they',\n",
       " 'allow',\n",
       " 'us',\n",
       " 'to',\n",
       " 'observe',\n",
       " 'patterns',\n",
       " ',',\n",
       " 'identify',\n",
       " 'central',\n",
       " 'tendencies',\n",
       " ',',\n",
       " 'and',\n",
       " 'assess',\n",
       " 'the',\n",
       " 'spread',\n",
       " 'or',\n",
       " 'dispersion',\n",
       " 'of',\n",
       " 'the',\n",
       " 'data',\n",
       " '.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokenzied_words=word_tokenize(my_text.lower())\n",
    "tokenzied_words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STOPWORD REMOVAL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'during', 'whom', \"needn't\", \"mustn't\", 'needn', 'while', 'doing', 'the', 'by', 'shan', 'than', \"you've\", 'ain', 'both', 'himself', 'or', 'they', 'some', 'but', 'and', 'few', 'for', 'he', 'only', 'was', 'with', 'aren', 'been', 'these', 'doesn', 'hadn', 'yourselves', 'their', 'what', 'too', 'which', 'him', \"aren't\", 'that', 'off', 'as', 'will', 'through', 'll', 'didn', 'm', 'itself', 'below', 'once', 'me', 'mightn', 'my', \"weren't\", 'down', 'over', 'weren', 'after', 'haven', 'if', 'in', \"mightn't\", 'then', 'under', 'd', 'o', 'above', 'can', 'yours', \"didn't\", 'do', 'there', \"wasn't\", 'when', \"hasn't\", \"isn't\", 'of', 'who', 'were', 'don', 'an', 'couldn', 'because', 'its', \"should've\", 'wouldn', 'yourself', \"shan't\", 'just', 'herself', 'isn', 'has', 'ma', 'having', 'have', 'here', 'is', 'now', \"you'll\", 'against', 'each', 'ours', 'to', 'themselves', 'on', 'very', 'between', \"you'd\", \"won't\", 'again', \"wouldn't\", 'mustn', 'about', \"couldn't\", 'those', 'further', 'out', \"doesn't\", ',', 'myself', 'are', 'how', 'hasn', 'did', 'you', 'y', 'your', 'more', 'wasn', 'ourselves', 't', \"she's\", 'not', 'all', 'a', 'am', 'theirs', \"hadn't\", 'nor', 'own', 'most', 'where', \"that'll\", 'other', 're', \"it's\", \"shouldn't\", 'so', 'it', 'before', 'no', 'same', 'at', 'shouldn', \"you're\", 'she', 'until', 'why', 'won', 'does', 's', 'from', '.', \"don't\", 'such', 'should', 'her', 'this', 'them', 'being', 'had', 'we', 'his', 'our', \"haven't\", 'be', 'hers', 'into', 'i', 've', 'any', 'up'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Vaishnavi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stopwords=set(stopwords.words('English'))\n",
    "stopwords.add('.')\n",
    "stopwords.add(',')\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['histogram', 'graphical', 'representation', 'distribution', 'dataset', 'provides', 'visual', 'summary', 'frequencies', 'counts', 'data', 'points', 'falling', 'within', 'different', 'ranges', 'also', 'known', 'bins', 'intervals.in', 'histogram', 'x-axis', 'represents', 'range', 'values', 'dataset', 'divided', 'equal-sized', 'bins', 'y-axis', 'represents', 'frequency', 'count', 'data', 'points', 'falling', 'within', 'bin', 'height', 'bar', 'histogram', 'corresponds', 'number', 'data', 'points', 'falling', 'within', 'bin.histograms', 'commonly', 'used', 'understand', 'distribution', 'continuous', 'numerical', 'variables', 'allow', 'us', 'observe', 'patterns', 'identify', 'central', 'tendencies', 'assess', 'spread', 'dispersion', 'data']\n"
     ]
    }
   ],
   "source": [
    "filtered_text=[]\n",
    "\n",
    "for word in tokenzied_words:\n",
    "    if word not in stopwords:\n",
    "        filtered_text.append(word)\n",
    "        \n",
    "print(filtered_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POS TAGGING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Vaishnavi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('histogram', 'JJ'),\n",
       " ('graphical', 'JJ'),\n",
       " ('representation', 'NN'),\n",
       " ('distribution', 'NN'),\n",
       " ('dataset', 'NN'),\n",
       " ('provides', 'VBZ'),\n",
       " ('visual', 'JJ'),\n",
       " ('summary', 'JJ'),\n",
       " ('frequencies', 'NNS'),\n",
       " ('counts', 'VBZ'),\n",
       " ('data', 'NNS'),\n",
       " ('points', 'NNS'),\n",
       " ('falling', 'VBG'),\n",
       " ('within', 'IN'),\n",
       " ('different', 'JJ'),\n",
       " ('ranges', 'NNS'),\n",
       " ('also', 'RB'),\n",
       " ('known', 'VBN'),\n",
       " ('bins', 'NNS'),\n",
       " ('intervals.in', 'JJ'),\n",
       " ('histogram', 'JJ'),\n",
       " ('x-axis', 'JJ'),\n",
       " ('represents', 'VBZ'),\n",
       " ('range', 'NN'),\n",
       " ('values', 'NNS'),\n",
       " ('dataset', 'VB'),\n",
       " ('divided', 'VBN'),\n",
       " ('equal-sized', 'JJ'),\n",
       " ('bins', 'NNS'),\n",
       " ('y-axis', 'JJ'),\n",
       " ('represents', 'VBZ'),\n",
       " ('frequency', 'NN'),\n",
       " ('count', 'NN'),\n",
       " ('data', 'NNS'),\n",
       " ('points', 'NNS'),\n",
       " ('falling', 'VBG'),\n",
       " ('within', 'IN'),\n",
       " ('bin', 'NN'),\n",
       " ('height', 'JJ'),\n",
       " ('bar', 'NN'),\n",
       " ('histogram', 'NN'),\n",
       " ('corresponds', 'VBZ'),\n",
       " ('number', 'NN'),\n",
       " ('data', 'NNS'),\n",
       " ('points', 'NNS'),\n",
       " ('falling', 'VBG'),\n",
       " ('within', 'IN'),\n",
       " ('bin.histograms', 'NNS'),\n",
       " ('commonly', 'RB'),\n",
       " ('used', 'VBD'),\n",
       " ('understand', 'JJ'),\n",
       " ('distribution', 'NN'),\n",
       " ('continuous', 'JJ'),\n",
       " ('numerical', 'JJ'),\n",
       " ('variables', 'NNS'),\n",
       " ('allow', 'VBP'),\n",
       " ('us', 'PRP'),\n",
       " ('observe', 'VBP'),\n",
       " ('patterns', 'NNS'),\n",
       " ('identify', 'VB'),\n",
       " ('central', 'JJ'),\n",
       " ('tendencies', 'NNS'),\n",
       " ('assess', 'IN'),\n",
       " ('spread', 'JJ'),\n",
       " ('dispersion', 'NN'),\n",
       " ('data', 'NNS')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "pos_tagging= pos_tag(filtered_text)\n",
    "pos_tagging"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noun (NN): Represents a person, place, thing, or idea. Example: \"cat\", \"book\", \"city\".\n",
    "Verb (VB): Represents an action, occurrence, or state. Example: \"run\", \"eat\", \"sleep\".\n",
    "Adjective (JJ): Describes or modifies a noun. Example: \"happy\", \"big\", \"red\".\n",
    "Adverb (RB): Modifies a verb, adjective, or another adverb. Example: \"quickly\", \"very\", \"often\".\n",
    "Pronoun (PRP): Replaces a noun. Example: \"he\", \"she\", \"it\".\n",
    "Preposition (IN): Shows a relationship between a noun and another word. Example: \"in\", \"on\", \"at\".\n",
    "Conjunction (CC): Connects words, phrases, or clauses. Example: \"and\", \"but\", \"or\".\n",
    "Determiner (DT): Specifies or identifies a noun. Example: \"the\", \"this\", \"some\".\n",
    "Interjection (UH): Expresses strong emotions or exclamations. Example: \"wow\", \"oh\", \"oops\"."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEMMING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import PorterStemmer\n",
    "\n",
    "ps=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['histogram', 'graphical', 'representation', 'distribution', 'dataset', 'provides', 'visual', 'summary', 'frequencies', 'counts', 'data', 'points', 'falling', 'within', 'different', 'ranges', 'also', 'known', 'bins', 'intervals.in', 'histogram', 'x-axis', 'represents', 'range', 'values', 'dataset', 'divided', 'equal-sized', 'bins', 'y-axis', 'represents', 'frequency', 'count', 'data', 'points', 'falling', 'within', 'bin', 'height', 'bar', 'histogram', 'corresponds', 'number', 'data', 'points', 'falling', 'within', 'bin.histograms', 'commonly', 'used', 'understand', 'distribution', 'continuous', 'numerical', 'variables', 'allow', 'us', 'observe', 'patterns', 'identify', 'central', 'tendencies', 'assess', 'spread', 'dispersion', 'data']\n",
      "['histogram', 'graphic', 'represent', 'distribut', 'dataset', 'provid', 'visual', 'summari', 'frequenc', 'count', 'data', 'point', 'fall', 'within', 'differ', 'rang', 'also', 'known', 'bin', 'intervals.in', 'histogram', 'x-axi', 'repres', 'rang', 'valu', 'dataset', 'divid', 'equal-s', 'bin', 'y-axi', 'repres', 'frequenc', 'count', 'data', 'point', 'fall', 'within', 'bin', 'height', 'bar', 'histogram', 'correspond', 'number', 'data', 'point', 'fall', 'within', 'bin.histogram', 'commonli', 'use', 'understand', 'distribut', 'continu', 'numer', 'variabl', 'allow', 'us', 'observ', 'pattern', 'identifi', 'central', 'tendenc', 'assess', 'spread', 'dispers', 'data']\n"
     ]
    }
   ],
   "source": [
    "stemmed_words= []\n",
    "\n",
    "for word in filtered_text:\n",
    "    stemmed_words.append(ps.stem(word))\n",
    "    \n",
    "print(filtered_text)\n",
    "print(stemmed_words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Vaishnavi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['histogram', 'graphical', 'representation', 'distribution', 'dataset', 'provides', 'visual', 'summary', 'frequencies', 'counts', 'data', 'points', 'falling', 'within', 'different', 'ranges', 'also', 'known', 'bins', 'intervals.in', 'histogram', 'x-axis', 'represents', 'range', 'values', 'dataset', 'divided', 'equal-sized', 'bins', 'y-axis', 'represents', 'frequency', 'count', 'data', 'points', 'falling', 'within', 'bin', 'height', 'bar', 'histogram', 'corresponds', 'number', 'data', 'points', 'falling', 'within', 'bin.histograms', 'commonly', 'used', 'understand', 'distribution', 'continuous', 'numerical', 'variables', 'allow', 'us', 'observe', 'patterns', 'identify', 'central', 'tendencies', 'assess', 'spread', 'dispersion', 'data']\n",
      "['histogram', 'graphical', 'representation', 'distribution', 'dataset', 'provides', 'visual', 'summary', 'frequency', 'count', 'data', 'point', 'falling', 'within', 'different', 'range', 'also', 'known', 'bin', 'intervals.in', 'histogram', 'x-axis', 'represents', 'range', 'value', 'dataset', 'divided', 'equal-sized', 'bin', 'y-axis', 'represents', 'frequency', 'count', 'data', 'point', 'falling', 'within', 'bin', 'height', 'bar', 'histogram', 'corresponds', 'number', 'data', 'point', 'falling', 'within', 'bin.histograms', 'commonly', 'used', 'understand', 'distribution', 'continuous', 'numerical', 'variable', 'allow', 'u', 'observe', 'pattern', 'identify', 'central', 'tendency', 'ass', 'spread', 'dispersion', 'data']\n"
     ]
    }
   ],
   "source": [
    "wl=WordNetLemmatizer()\n",
    "\n",
    "lemmatized_words=[]\n",
    "for word in filtered_text:\n",
    "    lemmatized_words.append(wl.lemmatize(word))\n",
    "    \n",
    "print(filtered_text)\n",
    "print(lemmatized_words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TERM FREQUENCY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_set=set(lemmatized_words)\n",
    "df= dict.fromkeys(words_set,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'histogram': 3, 'commonly': 1, 'understand': 1, 'data': 4, 'intervals.in': 1, 'identify': 1, 'frequency': 2, 'variable': 1, 'x-axis': 1, 'representation': 1, 'represents': 2, 'point': 3, 'spread': 1, 'provides': 1, 'dataset': 2, 'central': 1, 'dispersion': 1, 'also': 1, 'bar': 1, 'equal-sized': 1, 'numerical': 1, 'falling': 3, 'within': 3, 'known': 1, 'divided': 1, 'observe': 1, 'height': 1, 'different': 1, 'y-axis': 1, 'graphical': 1, 'range': 2, 'summary': 1, 'number': 1, 'distribution': 2, 'visual': 1, 'count': 2, 'value': 1, 'bin': 3, 'continuous': 1, 'tendency': 1, 'bin.histograms': 1, 'pattern': 1, 'u': 1, 'ass': 1, 'allow': 1, 'corresponds': 1, 'used': 1}\n"
     ]
    }
   ],
   "source": [
    "for word in lemmatized_words:\n",
    "    df[word]+=1\n",
    "    \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'histogram': 0.045454545454545456, 'commonly': 0.015151515151515152, 'understand': 0.015151515151515152, 'data': 0.06060606060606061, 'intervals.in': 0.015151515151515152, 'identify': 0.015151515151515152, 'frequency': 0.030303030303030304, 'variable': 0.015151515151515152, 'x-axis': 0.015151515151515152, 'representation': 0.015151515151515152, 'represents': 0.030303030303030304, 'point': 0.045454545454545456, 'spread': 0.015151515151515152, 'provides': 0.015151515151515152, 'dataset': 0.030303030303030304, 'central': 0.015151515151515152, 'dispersion': 0.015151515151515152, 'also': 0.015151515151515152, 'bar': 0.015151515151515152, 'equal-sized': 0.015151515151515152, 'numerical': 0.015151515151515152, 'falling': 0.045454545454545456, 'within': 0.045454545454545456, 'known': 0.015151515151515152, 'divided': 0.015151515151515152, 'observe': 0.015151515151515152, 'height': 0.015151515151515152, 'different': 0.015151515151515152, 'y-axis': 0.015151515151515152, 'graphical': 0.015151515151515152, 'range': 0.030303030303030304, 'summary': 0.015151515151515152, 'number': 0.015151515151515152, 'distribution': 0.030303030303030304, 'visual': 0.015151515151515152, 'count': 0.030303030303030304, 'value': 0.015151515151515152, 'bin': 0.045454545454545456, 'continuous': 0.015151515151515152, 'tendency': 0.015151515151515152, 'bin.histograms': 0.015151515151515152, 'pattern': 0.015151515151515152, 'u': 0.015151515151515152, 'ass': 0.015151515151515152, 'allow': 0.015151515151515152, 'corresponds': 0.015151515151515152, 'used': 0.015151515151515152}\n"
     ]
    }
   ],
   "source": [
    "tf={}\n",
    "\n",
    "total_words=len(lemmatized_words)\n",
    "\n",
    "for word, count in df.items():\n",
    "    tf[word]=count/total_words\n",
    "    \n",
    "print(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'histogram': 1.5947384557424684, 'commonly': 1.4488361674177337, 'understand': 1.4488361674177337, 'data': 1.6426987111217137, 'intervals.in': 1.4488361674177337, 'identify': 1.4488361674177337, 'frequency': 1.5350389068072148, 'variable': 1.4488361674177337, 'x-axis': 1.4488361674177337, 'representation': 1.4488361674177337, 'represents': 1.5350389068072148, 'point': 1.5947384557424684, 'spread': 1.4488361674177337, 'provides': 1.4488361674177337, 'dataset': 1.5350389068072148, 'central': 1.4488361674177337, 'dispersion': 1.4488361674177337, 'also': 1.4488361674177337, 'bar': 1.4488361674177337, 'equal-sized': 1.4488361674177337, 'numerical': 1.4488361674177337, 'falling': 1.5947384557424684, 'within': 1.5947384557424684, 'known': 1.4488361674177337, 'divided': 1.4488361674177337, 'observe': 1.4488361674177337, 'height': 1.4488361674177337, 'different': 1.4488361674177337, 'y-axis': 1.4488361674177337, 'graphical': 1.4488361674177337, 'range': 1.5350389068072148, 'summary': 1.4488361674177337, 'number': 1.4488361674177337, 'distribution': 1.5350389068072148, 'visual': 1.4488361674177337, 'count': 1.5350389068072148, 'value': 1.4488361674177337, 'bin': 1.5947384557424684, 'continuous': 1.4488361674177337, 'tendency': 1.4488361674177337, 'bin.histograms': 1.4488361674177337, 'pattern': 1.4488361674177337, 'u': 1.4488361674177337, 'ass': 1.4488361674177337, 'allow': 1.4488361674177337, 'corresponds': 1.4488361674177337, 'used': 1.4488361674177337}\n"
     ]
    }
   ],
   "source": [
    "n=len(df)\n",
    "idf=df\n",
    "\n",
    "for word,count in idf.items():\n",
    "    idf[word]=math.log10(n/count)\n",
    "    \n",
    "print(idf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tfidf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'histogram': 0.07248811162465765, 'commonly': 0.021952063142692935, 'understand': 0.021952063142692935, 'data': 0.09955749764374022, 'intervals.in': 0.021952063142692935, 'identify': 0.021952063142692935, 'frequency': 0.04651633050930954, 'variable': 0.021952063142692935, 'x-axis': 0.021952063142692935, 'representation': 0.021952063142692935, 'represents': 0.04651633050930954, 'point': 0.07248811162465765, 'spread': 0.021952063142692935, 'provides': 0.021952063142692935, 'dataset': 0.04651633050930954, 'central': 0.021952063142692935, 'dispersion': 0.021952063142692935, 'also': 0.021952063142692935, 'bar': 0.021952063142692935, 'equal-sized': 0.021952063142692935, 'numerical': 0.021952063142692935, 'falling': 0.07248811162465765, 'within': 0.07248811162465765, 'known': 0.021952063142692935, 'divided': 0.021952063142692935, 'observe': 0.021952063142692935, 'height': 0.021952063142692935, 'different': 0.021952063142692935, 'y-axis': 0.021952063142692935, 'graphical': 0.021952063142692935, 'range': 0.04651633050930954, 'summary': 0.021952063142692935, 'number': 0.021952063142692935, 'distribution': 0.04651633050930954, 'visual': 0.021952063142692935, 'count': 0.04651633050930954, 'value': 0.021952063142692935, 'bin': 0.07248811162465765, 'continuous': 0.021952063142692935, 'tendency': 0.021952063142692935, 'bin.histograms': 0.021952063142692935, 'pattern': 0.021952063142692935, 'u': 0.021952063142692935, 'ass': 0.021952063142692935, 'allow': 0.021952063142692935, 'corresponds': 0.021952063142692935, 'used': 0.021952063142692935}\n"
     ]
    }
   ],
   "source": [
    "tfidf={}\n",
    "\n",
    "for word, val in tf.items():\n",
    "    tfidf[word]=val*idf[word]\n",
    "    \n",
    "print(tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.33255687\n",
      "  0.         0.         0.33255687 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.41219567 0.\n",
      "  0.27605224 0.         0.         0.         0.         0.\n",
      "  0.41219567 0.         0.         0.         0.         0.\n",
      "  0.39282689 0.         0.         0.         0.         0.\n",
      "  0.         0.41219567 0.         0.         0.         0.\n",
      "  0.         0.         0.19641344 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.16985506 0.         0.         0.16985506 0.\n",
      "  0.137038   0.         0.         0.33971013 0.         0.\n",
      "  0.         0.         0.         0.16985506 0.09569338 0.137038\n",
      "  0.16985506 0.         0.         0.16985506 0.         0.16985506\n",
      "  0.11375392 0.16985506 0.         0.16985506 0.         0.\n",
      "  0.11375392 0.         0.         0.137038   0.16985506 0.16985506\n",
      "  0.         0.16985506 0.16985506 0.         0.         0.\n",
      "  0.24281054 0.19138676 0.         0.11375392 0.16985506 0.16985506\n",
      "  0.16985506 0.         0.137038   0.16985506 0.         0.16985506\n",
      "  0.         0.         0.32374739 0.         0.         0.\n",
      "  0.         0.         0.16985506 0.         0.16985506 0.11375392]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.29038472 0.         0.29038472 0.         0.         0.\n",
      "  0.         0.         0.35992438 0.         0.20277512 0.\n",
      "  0.         0.         0.         0.         0.29038472 0.\n",
      "  0.24104555 0.         0.35992438 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.1715059  0.20277512 0.         0.24104555 0.         0.\n",
      "  0.         0.         0.29038472 0.         0.         0.\n",
      "  0.         0.         0.34301179 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.24104555]\n",
      " [0.         0.         0.         0.19494764 0.         0.\n",
      "  0.         0.19494764 0.15728253 0.         0.         0.19494764\n",
      "  0.19494764 0.19494764 0.         0.         0.1098301  0.\n",
      "  0.         0.         0.15728253 0.         0.15728253 0.\n",
      "  0.1305587  0.         0.         0.         0.         0.19494764\n",
      "  0.1305587  0.19494764 0.         0.15728253 0.         0.\n",
      "  0.         0.         0.         0.19494764 0.19494764 0.\n",
      "  0.27868078 0.1098301  0.         0.1305587  0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.19494764 0.37157438 0.         0.31456505 0.19494764\n",
      "  0.         0.19494764 0.         0.19494764 0.         0.1305587 ]\n",
      " [0.26333117 0.         0.26333117 0.         0.         0.26333117\n",
      "  0.         0.         0.         0.         0.26333117 0.\n",
      "  0.         0.         0.         0.         0.14835619 0.\n",
      "  0.         0.26333117 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.26333117 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.26333117\n",
      "  0.12547871 0.14835619 0.26333117 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.26333117 0.\n",
      "  0.26333117 0.         0.25095743 0.26333117 0.21245393 0.\n",
      "  0.26333117 0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorize=TfidfVectorizer()\n",
    "\n",
    "tf_idf_vectors=vectorize.fit_transform(tokenzied_text)\n",
    "\n",
    "tf_idf_matrix=tf_idf_vectors.toarray()\n",
    "\n",
    "print(tf_idf_matrix)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TF-IDF score is obtained by multiplying the TF and IDF values together. The higher the TF-IDF score for a term in a document, the more important or relevant that term is to that document."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
